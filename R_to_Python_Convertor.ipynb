{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It89APiAtTUF"
   },
   "source": [
    "# Project Overview: R to Python Code Convertor\n",
    "\n",
    "The goal of this project is to\n",
    "*   Convert R to Python Code\n",
    "*   Maintain desired outputs and speed up time to completion when possible\n",
    "\n",
    "Why this is useful\n",
    "*   Applies to almost any current data science business use case regarding modernization\n",
    "*   Many companies are transitioning R code to Python, this helps speed up the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1r6AyvfNHwX"
   },
   "source": [
    "# STEP 0: Installs, Imports, API Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzor9pmnNYwN"
   },
   "source": [
    "## Installs\n",
    "Since we're using a Google Colab to run this, we need to install R and rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6q9WWqTxVpwL",
    "outputId": "4d6ff0bc-6cbe-47c3-a817-0abaf63eb147"
   },
   "outputs": [],
   "source": [
    "!apt-get update -qq\n",
    "!apt-get install -y r-base r-base-dev\n",
    "\n",
    "!pip install rpy2\n",
    "\n",
    "# Install commonly used R packages (optional)\n",
    "!Rscript -e \"install.packages(c('dplyr', 'ggplot2'), repos='https://cloud.r-project.org', quiet=TRUE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj8v6g7ENXgv"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUbHZHowMpvB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from google.colab import drive, userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkz_3K7jYfsq"
   },
   "source": [
    "Was having issues with rpy2 import and pandas2ri; meaning the user couldn't run R code in the Gradio UI\n",
    "\n",
    "This error handling should let the user know if they can execute R code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdBwIBwkRFwm",
    "outputId": "f0fa1141-9656-403c-99fc-c01c55879c62"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import rpy2.robjects as robjects\n",
    "    R_AVAILABLE = True\n",
    "    print(\"SUCCESS! rpy2 successfully imported - R code execution available\")\n",
    "\n",
    "    # Try to activate pandas conversion (optional, not critical)\n",
    "    try:\n",
    "        from rpy2.robjects import pandas2ri\n",
    "        pandas2ri.activate()\n",
    "        print(\"pandas2ri activated\")\n",
    "    except (ImportError, AttributeError):\n",
    "        try:\n",
    "            # Try alternative import for newer versions\n",
    "            import rpy2.robjects.conversion\n",
    "            print(\"rpy2 conversion available\")\n",
    "        except ImportError:\n",
    "            print(\"pandas2ri not available, but basic R execution will work\")\n",
    "except ImportError as e:\n",
    "    R_AVAILABLE = False\n",
    "    robjects = None\n",
    "    print(\"Warning: rpy2 not installed. R code execution will be disabled.\")\n",
    "    print(\"\\nTo enable R execution in Google Colab, run these commands:\")\n",
    "    print(\"  !apt-get update -qq\")\n",
    "    print(\"  !apt-get install -y r-base r-base-dev\")\n",
    "    print(\"  !pip install rpy2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ITb14kwNdb2"
   },
   "source": [
    "## Sign into HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYW8kQYtF-3L",
    "outputId": "d12a7f17-a638-44cd-8c13-45059a48e647"
   },
   "outputs": [],
   "source": [
    "hf_token = userdata.get('HF_TOKEN')\n",
    "if hf_token and hf_token.startswith(\"hf_\"):\n",
    "  print(\"HF key looks good so far\")\n",
    "else:\n",
    "  print(\"HF key is not set - please click the key in the left sidebar\")\n",
    "\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh_7HBo_NHKM"
   },
   "source": [
    "## Get other API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk7K11O-NIg_",
    "outputId": "e3ec2dda-df15-48da-9797-1442be879a20"
   },
   "outputs": [],
   "source": [
    "gemini_token = userdata.get('GEMINI_API_KEY')\n",
    "if gemini_token and gemini_token.startswith(\"AIza\"):\n",
    "  print(\"Gemini key looks good so far\")\n",
    "else:\n",
    "  print(\"Gemini key is not set - please click the key in the left sidebar\")\n",
    "\n",
    "openai_token = userdata.get('OPENAI_API_KEY')\n",
    "if openai_token and openai_token.startswith(\"sk-\"):\n",
    "  print(\"OpenAI key looks good so far\")\n",
    "else:\n",
    "  print(\"OpenAI key is not set - please click the key in the left sidebar\")\n",
    "\n",
    "groq_token = userdata.get('GROQ_API_KEY')\n",
    "if groq_token and groq_token.startswith(\"gsk\"):\n",
    "  print(\"Groq key looks good so far\")\n",
    "else:\n",
    "  print(\"Groq key is not set - please click the key in the left sidebar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IydFF99iNNYr"
   },
   "source": [
    "## Connect to Client Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAW03EQVNPh2"
   },
   "outputs": [],
   "source": [
    "openai = OpenAI(api_key=openai_token)\n",
    "\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "\n",
    "gemini = OpenAI(api_key=gemini_token, base_url=gemini_url)\n",
    "groq = OpenAI(api_key=groq_token, base_url=groq_url)\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN4UlSOTNU-P"
   },
   "source": [
    "## Set up Model-Client Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoLYzN1rc6gx"
   },
   "source": [
    "**Note**: Used Artificial Analysis Leaderboard and filtered to cheap/open-source models that were best at Coding Intelligence\n",
    "* LiveCodeBench and SciCode metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUGWgwJhdkK8"
   },
   "source": [
    "**Future Work**: If I was willing to pay more, I would have leveraged these additional models:\n",
    "- Gemini 3 Pro\n",
    "- Gemini 3 Flash\n",
    "- GPT 5.2\n",
    "- Claude Opus 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OaGXWp_NWzX"
   },
   "outputs": [],
   "source": [
    "models = [\"openai/gpt-oss-120b\", \"gpt-5-nano\", \"gemini_2.5-flash-lite\", \"qwen2.5-coder\", \"deepseek-coder-v2\", \"gpt-oss:20b\"]\n",
    "\n",
    "clients = {\n",
    "    \"gpt-5-nano\": openai,\n",
    "    \"gemini_2.5-flash-lite\": gemini,\n",
    "    \"openai/gpt-oss-120b\": groq,\n",
    "    \"qwen2.5-coder\": ollama,\n",
    "    \"deepseek-coder-v2\": ollama,\n",
    "    \"gpt-oss:20b\": ollama\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GLpveo8cgzq"
   },
   "source": [
    "# STEP 1: Design the Prompt Engine\n",
    "Allows us to tell the LLM *what to do*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q8VHUWKcAAR"
   },
   "source": [
    "## System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mS7u43DNP0yU"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Your task is to convert R code into optimized, high-performance Python code.\n",
    "Follow these guidelines:\n",
    "1. Use efficient Python libraries (numpy, pandas, scipy, etc.)\n",
    "2. Vectorize operations where possible\n",
    "3. Maintain identical functionality and output\n",
    "4. Use Pythonic idioms and best practices\n",
    "5. Include necessary imports\n",
    "6. Add brief comments explaining key conversions\n",
    "7. If the user is writing a DataFrame or CSV, print out that CSV output\n",
    "\n",
    "Respond only with Python code that can be executed directly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def user_prompt_for(r_code):\n",
    "    return f\"\"\"\n",
    "Convert this R code to optimized Python code that produces identical output with better performance.\n",
    "\n",
    "Requirements:\n",
    "- Use numpy, pandas, and other efficient libraries\n",
    "- Vectorize operations where possible\n",
    "- Include all necessary imports at the top\n",
    "- Maintain the same output format\n",
    "- Optimize for speed\n",
    "\n",
    "R code to convert:\n",
    "\n",
    "```r\n",
    "{r_code}\n",
    "```\n",
    "\n",
    "Respond with executable Python code only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o09tl1obNsqN"
   },
   "outputs": [],
   "source": [
    "def messages_for(r_code):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(r_code)}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wt22rJFcYFW"
   },
   "source": [
    "# STEP 3: Core Code Generation Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIyb0UjEapPn"
   },
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MzpNJoOQGf5"
   },
   "outputs": [],
   "source": [
    "# Cleans markdown code blocks from the LLM response\n",
    "def clean_code_response(response_text):\n",
    "    response_text = response_text.replace('```python', '').replace('```r', '').replace('```', '')\n",
    "    return response_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc00m_Z4arqQ"
   },
   "source": [
    "## Conversion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GM8B2FrQNWr"
   },
   "outputs": [],
   "source": [
    "# Converts R code to Python using the model of choice\n",
    "def convert_r_to_python(model, r_code):\n",
    "    try:\n",
    "        client = clients[model]\n",
    "        if model == \"gpt-5-nano\":\n",
    "          response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages_for(r_code)\n",
    "        )\n",
    "        else:\n",
    "          response = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=messages_for(r_code),\n",
    "              temperature=0.3  # Lower temperature for more consistent code generation\n",
    "          )\n",
    "        python_code = response.choices[0].message.content\n",
    "        python_code = clean_code_response(python_code)\n",
    "        return python_code\n",
    "    except Exception as e:\n",
    "        return f\"# Error during conversion:\\n# {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLNf0yDpatA_"
   },
   "source": [
    "## Execution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oc0dHMXMQPdT"
   },
   "outputs": [],
   "source": [
    "# Runs the R code and returns the output with a timing metric\n",
    "def run_r_code(code):\n",
    "    # Need to handle if R isn't available\n",
    "    if not R_AVAILABLE:\n",
    "        return \"R execution not available (rpy2 not installed)\\nPlease install R and rpy2 to run R code.\", 0.0\n",
    "\n",
    "    try:\n",
    "        import tempfile\n",
    "        import os\n",
    "\n",
    "        # Create a temporary file to capture output\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            temp_path = f.name\n",
    "\n",
    "        # Use forward slashes for R path (works on all platforms)\n",
    "        r_temp_path = temp_path.replace('\\\\', '/')\n",
    "\n",
    "        # Wrap the R code to capture all output including cat() statements\n",
    "        wrapped_code = f\"\"\"\n",
    "        con <- file(\"{r_temp_path}\", open=\"wt\")\n",
    "        sink(con, type=\"output\")\n",
    "        sink(con, type=\"message\")\n",
    "        {code}\n",
    "        sink(type=\"message\")\n",
    "        sink(type=\"output\")\n",
    "        close(con)\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        robjects.r(wrapped_code)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        # Read the captured output\n",
    "        with open(temp_path, 'r') as f:\n",
    "            output = f.read()\n",
    "\n",
    "        # Clean up temp file\n",
    "        try:\n",
    "            os.unlink(temp_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if not output.strip():\n",
    "            output = \"(No output produced)\"\n",
    "\n",
    "        return output, execution_time\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return f\"Error executing R code:\\n{str(e)}\\n\\nTraceback:\\n{traceback.format_exc()}\", 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9OCLWfyQRfE"
   },
   "outputs": [],
   "source": [
    "# Runs the Python code and returns the output with a timing metric\n",
    "def run_python_code(code):\n",
    "    globals_dict = {\n",
    "        \"__builtins__\": __builtins__,\n",
    "        \"np\": None,  # Numpy will be imported by the code\n",
    "        \"pd\": None,  # Pandas will be imported by the code\n",
    "        \"time\": time # Time will be imported by the code\n",
    "    }\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        exec(code, globals_dict)\n",
    "        end_time = time.time()\n",
    "\n",
    "        output = buffer.getvalue()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        return output, execution_time\n",
    "    except Exception as e:\n",
    "        return f\"Error executing Python code:\\n{str(e)}\", 0.0\n",
    "    finally:\n",
    "        sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJM2dgxeavCZ"
   },
   "source": [
    "## Comparison Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKOPCLM7QTN9"
   },
   "outputs": [],
   "source": [
    "# Runs both R and Python code and compares the output and timing metrics\n",
    "def compare_execution(r_code, python_code):\n",
    "    r_output, r_time = run_r_code(r_code)\n",
    "    py_output, py_time = run_python_code(python_code)\n",
    "\n",
    "    # Timing Comparison\n",
    "    if r_time > 0 and py_time > 0:\n",
    "        speedup = r_time / py_time\n",
    "        speedup_text = f\"{'='*50}\\nPerformance Comparison:\\n{'='*50}\\n\"                     # Nice header\n",
    "        speedup_text += f\"R execution time: {r_time:.6f} seconds\\n\"\n",
    "        speedup_text += f\"Python execution time: {py_time:.6f} seconds\\n\"\n",
    "        speedup_text += f\"Speedup: {speedup:.2f}x {'faster' if speedup > 1 else 'slower'}\\n\"\n",
    "        speedup_text += f\"{'='*50}\"                                                             # Nice footer\n",
    "    else:\n",
    "        speedup_text = \"\\n\\nTiming information not available.\"\n",
    "\n",
    "    return r_output, py_output, speedup_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jLJBkRzQ2x3"
   },
   "source": [
    "# STEP 4: Gradio User Interface\n",
    "Wrap everything in Gradio for publication\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPx4Aeprl1N_"
   },
   "source": [
    "## Sample R DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHx7vpOPgDBz"
   },
   "outputs": [],
   "source": [
    "sample_r_football_df = \"\"\"\n",
    "library(tibble)\n",
    "\n",
    "df <- tibble::tribble(\n",
    "  ~player,   ~team, ~week, ~attempts, ~passing_yards, ~pass_td, ~rush_td,\n",
    "  \"Stafford\",\"LAR\",   9,      27,          240,          2,        0,\n",
    "  \"Stafford\",\"LAR\",  10,      34,          310,          3,        0,\n",
    "  \"Stafford\",\"LAR\",  11,      31,          198,          1,        0,\n",
    "  \"Young\",   \"CAR\",   9,      29,          179,          1,        0,\n",
    "  \"Young\",   \"CAR\",  10,      33,          205,          1,        0,\n",
    "  \"Young\",   \"CAR\",  11,      28,           NA,          0,        0,\n",
    "  \"Allen\",   \"BUF\",  10,      38,          287,          2,        1,\n",
    "  \"Allen\",   \"BUF\",  11,      35,          312,          3,        1\n",
    ")\n",
    "\n",
    "teams <- tibble::tribble(\n",
    "  ~team, ~division,\n",
    "  \"LAR\", \"NFC West\",\n",
    "  \"CAR\", \"NFC South\",\n",
    "  \"BUF\", \"AFC East\"\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMVyZrehrTkU"
   },
   "source": [
    "## Sample R Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwogkcLOm6-u"
   },
   "outputs": [],
   "source": [
    "sample_r_basic = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  select(player, team, yds = passing_yards)\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_filter = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  filter(team == \"LAR\", week >= 10, passing_yards > 200)\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_mutate = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  mutate(\n",
    "    total_td = pass_td + rush_td,\n",
    "    ypa = passing_yards / attempts\n",
    "  ) %>%\n",
    "  select(player, week, total_td, ypa)\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_arrange = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  arrange(desc(passing_yards), week)\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_groupby = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  group_by(team) %>%\n",
    "  summarise(\n",
    "    games = n(),\n",
    "    avg_yds = mean(passing_yards),\n",
    "    max_yds = max(passing_yards)\n",
    "  ) %>%\n",
    "  arrange(desc(avg_yds))\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_window = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  group_by(team) %>%\n",
    "  mutate(team_avg_yds = mean(passing_yards)) %>%\n",
    "  ungroup() %>%\n",
    "  select(player, team, week, passing_yards, team_avg_yds)\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_distinct = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  distinct(team, player)\n",
    "\n",
    "print(out)\n",
    "\"\"\"\n",
    "\n",
    "sample_r_summarize = sample_r_football_df + \"\"\"\n",
    "library(dplyr)\n",
    "\n",
    "out <- df %>%\n",
    "  group_by(team) %>%\n",
    "  summarise(\n",
    "    unique_players = n_distinct(player),\n",
    "    avg_yds_no_na = mean(passing_yards, na.rm = TRUE)\n",
    "  )\n",
    "\n",
    "print(out)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syjQXvFnrVDQ"
   },
   "source": [
    "## Gradio App Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "katlyJZeQfL7",
    "outputId": "a25b7c1a-0229-4e0d-91e5-bd05aebd4d48"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Monochrome(), title=\"R to Python Converter\") as ui:\n",
    "    gr.Markdown(\"# Nikhil Gavini's R to Python Code Converter\")\n",
    "    gr.Markdown(\"### LLM converts R code to optimized Python and compares performance\")\n",
    "    gr.Markdown(\"Note: You should always verify the output instead of blindly trusting the results!\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            r_code = gr.Code(\n",
    "                label=\"R Code (Original)\",\n",
    "                value=sample_r_basic,\n",
    "                language=\"r\",\n",
    "                lines=20\n",
    "            )\n",
    "        with gr.Column(scale=6):\n",
    "            python_code = gr.Code(\n",
    "                label=\"Python Code (Generated)\",\n",
    "                value=\"\",\n",
    "                language=\"python\",\n",
    "                lines=20\n",
    "            )\n",
    "\n",
    "    with gr.Row(elem_classes=[\"controls\"]):\n",
    "        r_run_btn = gr.Button(\"Run R\", elem_classes=[\"run-btn\"])\n",
    "        model_dropdown = gr.Dropdown(\n",
    "            models,\n",
    "            value=models[0] if models else None,\n",
    "            label=\"Model\",\n",
    "            scale=2\n",
    "        )\n",
    "        convert_btn = gr.Button(\"Convert to Python\", elem_classes=[\"convert-btn\"], scale=2)\n",
    "        py_run_btn = gr.Button(\"Run Python\", elem_classes=[\"run-btn\"])\n",
    "        compare_btn = gr.Button(\"Compare Both\", elem_classes=[\"run-btn\"], scale=2)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            gr.Markdown(\"### Example R Code Templates\")\n",
    "            with gr.Row():\n",
    "                basic_btn = gr.Button(\"Basic Select\", size=\"sm\")\n",
    "                filter_btn = gr.Button(\"Filter DataFrame\", size=\"sm\")\n",
    "                mutate_btn = gr.Button(\"Mutate DataFrame\", size=\"sm\")\n",
    "                arrange_btn = gr.Button(\"Arrange\", size=\"sm\")\n",
    "                groupby_btn = gr.Button(\"Group By\", size=\"sm\")\n",
    "                window_btn = gr.Button(\"Window\", size=\"sm\")\n",
    "                distinct_btn = gr.Button(\"Distinct\", size=\"sm\")\n",
    "                summarize_btn = gr.Button(\"Summarize\", size=\"sm\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            r_output = gr.TextArea(\n",
    "                label=\"R Output\",\n",
    "                lines=10,\n",
    "                elem_classes=[\"r-out\"]\n",
    "            )\n",
    "        with gr.Column(scale=6):\n",
    "            py_output = gr.TextArea(\n",
    "                label=\"Python Output\",\n",
    "                lines=10,\n",
    "                elem_classes=[\"py-out\"]\n",
    "            )\n",
    "\n",
    "    with gr.Row():\n",
    "        comparison_output = gr.TextArea(\n",
    "            label=\"Performance Comparison\",\n",
    "            lines=6,\n",
    "            elem_classes=[\"py-out\"]\n",
    "        )\n",
    "\n",
    "    # Event handlers\n",
    "    convert_btn.click(\n",
    "        fn=convert_r_to_python,\n",
    "        inputs=[model_dropdown, r_code],\n",
    "        outputs=[python_code]\n",
    "    )\n",
    "\n",
    "    r_run_btn.click(\n",
    "        fn=lambda code: run_r_code(code)[0],\n",
    "        inputs=[r_code],\n",
    "        outputs=[r_output]\n",
    "    )\n",
    "\n",
    "    py_run_btn.click(\n",
    "        fn=lambda code: run_python_code(code)[0],\n",
    "        inputs=[python_code],\n",
    "        outputs=[py_output]\n",
    "    )\n",
    "\n",
    "    compare_btn.click(\n",
    "        fn=compare_execution,\n",
    "        inputs=[r_code, python_code],\n",
    "        outputs=[r_output, py_output, comparison_output]\n",
    "    )\n",
    "\n",
    "    # Example buttons\n",
    "    basic_btn.click(lambda: sample_r_basic, outputs=[r_code])\n",
    "    filter_btn.click(lambda: sample_r_filter, outputs=[r_code])\n",
    "    mutate_btn.click(lambda: sample_r_mutate, outputs=[r_code])\n",
    "    arrange_btn.click(lambda: sample_r_arrange, outputs=[r_code])\n",
    "    groupby_btn.click(lambda: sample_r_groupby, outputs=[r_code])\n",
    "    window_btn.click(lambda: sample_r_window, outputs=[r_code])\n",
    "    distinct_btn.click(lambda: sample_r_distinct, outputs=[r_code])\n",
    "    summarize_btn.click(lambda: sample_r_summarize, outputs=[r_code])\n",
    "\n",
    "ui.launch(share = False, inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FxP-pStQe-I"
   },
   "source": [
    "# Step 5: Testing Results\n",
    "\n",
    "Ran the comparison 3 times and took the average of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLvhMXzgo-6i"
   },
   "source": [
    "**Verdict**: openai/gpt-oss-120b consistently yielded the best Speedup Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPN1xa7doSXe"
   },
   "source": [
    "**Test Case**: Basic Select\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 6.61\n",
    "- gpt-5-nano Speedup Factor: 6.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eng2gWpSoojC"
   },
   "source": [
    "**Test Case**: Filter\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 10.44\n",
    "- gpt-5-nano Speedup Factor: 8.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nT6pWw0Qo041"
   },
   "source": [
    "**Test Case**: Mutate\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 10.35\n",
    "- gpt-5-nano Speedup Factor: 7.39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj9Bssypo0oz"
   },
   "source": [
    "**Test Case**: Arrange\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 10.86\n",
    "- gpt-5-nano Speedup Factor: 4.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYQL6S5Ro0aR"
   },
   "source": [
    "**Test Case**: Group By\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 4.10\n",
    "- gpt-5-nano Speedup Factor: 3.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CKm1Zc-o0Kd"
   },
   "source": [
    "**Test Case**: Window\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 5.92\n",
    "- gpt-5-nano Speedup Factor: 5.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3aoRfxhoz3a"
   },
   "source": [
    "**Test Case**: Distinct\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 5.75\n",
    "- gpt-5-nano Speedup Factor: 4.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3CiPleHozhb"
   },
   "source": [
    "**Test Case**: Summarize\n",
    "\n",
    "- openai/gpt-oss-120b Speedup Factor: 3.24\n",
    "- gpt-5-nano Speedup Factor: 2.33"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
